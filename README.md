# Egalitarian-AI
​Egalitarianism is a school of thought rooted in the belief that all people are fundamentally equal and should be treated as such. It is a philosophy that prioritizes social equality and the removal of inequalities, particularly in political, economic, and social life. 
​The word ["egalitarianism"](https://github.com/JoeFanning/Egalitarian-AI/blob/main/Egalitarianism%20research%20%20resources) comes from the French word "égal," which means "equal" or "level." It emerged during the French Revolution in the late 18th century when people were fighting for a society where everyone had the same rights and opportunities, no matter their background.

Egalitarian AI derives it's name from egalitarianism. Egalitarian AI would be considered an encompassing higher order for Ethical AI.
It's not just a set of rules for a model to adhere too, but a philosophical framework that guides the design and purpose of the entire AI system and its integration into society. It asks, "Does this system contribute to a more equal and just society? Is it helping to dismantle systemic inequalities?"

Technical development

In machine learning an egalitarian model would operate at a higher level of abstraction than an ethical model.
All the models of the AI system would be processed individually by the Ethical AI. Then all these processed models would be collectively analysed by the Egalitarian-AI. 

Stage 1: The Ethical AI Layer (Individual Model Processing)
​This is the "local" or "micro" level of analysis. In this stage, each individual machine learning model or component within the larger AI system would be rigorously audited to ensure it meets a set of predefined ethical standards. This would be a form of automated quality control for fairness, transparency, and accountability.
​Technically, this would involve a suite of automated tools and metrics applied to each model:
​Bias Detection and Fairness Audits: Before a model is deployed, an Ethical AI layer would run a series of fairness tests. It would use metrics like Disparate Impact, Equal Opportunity Difference, or Statistical Parity to check for bias across different demographic subgroups.
​Explainability (XAI): The layer would produce a detailed explainability report for each model using techniques like SHAP (SHapley Additive exPlanations) or LIME (Local Interpretable Model-agnostic Explanations). This would ensure that an operator can understand why a particular model is making its decisions.
​Privacy and Robustness Checks: Automated scans would check for vulnerabilities like data leakage or susceptibility to adversarial attacks. The goal is to ensure the model is secure and protects user data.
​This stage ensures that every single component of the AI system is "ethically sound" on its own, like checking that every individual part of a car is working correctly before assembly.

​Stage 2: The Egalitarian AI Layer (Collective Analysis)
​This is the "global" or "macro" level of analysis. The Egalitarian-AI layer operates at a higher level of abstraction, taking the ethically-vetted models and analyzing their collective impact on the system and society as a whole. Its goal is to optimize for a more just and equal outcome, rather than just local fairness.
​Technically, this layer would function as a system-wide monitoring and control hub:
​Systemic Feedback Loop Analysis: The Egalitarian-AI would monitor how the outputs of multiple models interact. For example, an ethical hiring model might select candidates from certain regions, while a separate ethical loan-approval model might favor applicants from other regions. The Egalitarian-AI would detect if the collective effect of these models is to reinforce or create new forms of systemic inequality between those regions.
​External Data Integration and Impact Measurement: This is a key differentiator. The Egalitarian-AI would not just use internal data but would also integrate with external, real-world data streams (e.g., census data, public health records, economic indicators). It would then analyze the system's overall impact. For example, "Is the deployment of our educational AI system actually narrowing the academic achievement gap, or is it only benefiting students in well-resourced schools?"
​Resource and Opportunity Allocation: If the AI system is a suite of services, the Egalitarian-AI would ensure the distribution of these services is equitable. It might actively shift resources or prioritize service access for historically underserved communities to correct for systemic imbalances.
​Macro-Level Optimization: The Egalitarian-AI's objective function would not be a simple metric like accuracy or fairness score, but a complex, multi-variable function that seeks to maximize social equality. It might recommend re-calibrating individual models or re-configuring the entire system to achieve a better societal outcome.
​Analogy: A City's Infrastructure
​This two-tiered technical structure can be likened to the way a city's infrastructure is planned and maintained:
​Ethical AI: An ethical approach would be like a building inspector. They would ensure that each individual building (an AI model) is constructed to code, is safe, and has proper access for people with disabilities.
​Egalitarian AI: An egalitarian approach would be like the city planner. They would look at all the buildings together and ask: "Are we building a city where everyone has equal access to housing, jobs, and parks? Are we building a city that actively promotes equity and breaks down historical segregation, or are we just making sure that the new construction doesn't violate existing rules?"
​It is a framework to design AI systems for both local ethics and global justice.

Joe Fanning Den Haag Centrum Aug 2025

